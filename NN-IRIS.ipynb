{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c705710b-6428-4e30-b8ca-f936ee525ebc",
   "metadata": {},
   "source": [
    "## NN-IRIS\n",
    "\n",
    "Create a neural network model to predict an Iris class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b026e33-0e14-47ab-af8b-ec1dc251d346",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-09 14:54:13.155747: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-09 14:54:14.794723: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5845203-6712-44ac-8c7b-f85acd7da40c",
   "metadata": {},
   "source": [
    "## 1. Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fa8385-d898-482f-bff8-89269faa04bf",
   "metadata": {},
   "source": [
    "### 1.1 Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "066e1685-fce1-4c98-a3dc-e88333f50178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sepal length in cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sepal width in cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>petal length in cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>petal width in cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>class</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                names\n",
       "0  sepal length in cm\n",
       "1   sepal width in cm\n",
       "2  petal length in cm\n",
       "3   petal width in cm\n",
       "4               class"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = pd.read_csv(\"data/iris names.txt\", names=['names'])\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ca8a936-0f6d-4cea-8bde-c14c51da8a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length in cm</th>\n",
       "      <th>sepal width in cm</th>\n",
       "      <th>petal length in cm</th>\n",
       "      <th>petal width in cm</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length in cm  sepal width in cm  petal length in cm  \\\n",
       "0                   5.1                3.5                 1.4   \n",
       "1                   4.9                3.0                 1.4   \n",
       "2                   4.7                3.2                 1.3   \n",
       "3                   4.6                3.1                 1.5   \n",
       "4                   5.0                3.6                 1.4   \n",
       "..                  ...                ...                 ...   \n",
       "145                 6.7                3.0                 5.2   \n",
       "146                 6.3                2.5                 5.0   \n",
       "147                 6.5                3.0                 5.2   \n",
       "148                 6.2                3.4                 5.4   \n",
       "149                 5.9                3.0                 5.1   \n",
       "\n",
       "     petal width in cm  class  \n",
       "0                  0.2      1  \n",
       "1                  0.2      1  \n",
       "2                  0.2      1  \n",
       "3                  0.2      1  \n",
       "4                  0.2      1  \n",
       "..                 ...    ...  \n",
       "145                2.3      3  \n",
       "146                1.9      3  \n",
       "147                2.0      3  \n",
       "148                2.3      3  \n",
       "149                1.8      3  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/iris2.data\", sep=\"\\t\", names=columns[\"names\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0305fae8-ea1f-4782-bbc0-c34c4cd8a259",
   "metadata": {},
   "source": [
    "### 1.2 Split data\n",
    "\n",
    "Split data to train and test subsets using `train_test_split()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "185cbcee-87a3-4d89-9b71-ad65b138a142",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"class\", axis=1)\n",
    "y = df[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4d6e5f8-e348-4531-a3fc-9ed634ac1d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length in cm</th>\n",
       "      <th>sepal width in cm</th>\n",
       "      <th>petal length in cm</th>\n",
       "      <th>petal width in cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length in cm  sepal width in cm  petal length in cm  \\\n",
       "0                   5.1                3.5                 1.4   \n",
       "1                   4.9                3.0                 1.4   \n",
       "2                   4.7                3.2                 1.3   \n",
       "3                   4.6                3.1                 1.5   \n",
       "4                   5.0                3.6                 1.4   \n",
       "..                  ...                ...                 ...   \n",
       "145                 6.7                3.0                 5.2   \n",
       "146                 6.3                2.5                 5.0   \n",
       "147                 6.5                3.0                 5.2   \n",
       "148                 6.2                3.4                 5.4   \n",
       "149                 5.9                3.0                 5.1   \n",
       "\n",
       "     petal width in cm  \n",
       "0                  0.2  \n",
       "1                  0.2  \n",
       "2                  0.2  \n",
       "3                  0.2  \n",
       "4                  0.2  \n",
       "..                 ...  \n",
       "145                2.3  \n",
       "146                1.9  \n",
       "147                2.0  \n",
       "148                2.3  \n",
       "149                1.8  \n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fd7bc33-28bd-4647-ade0-991586e87270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1      2      3\n",
       "0     True  False  False\n",
       "1     True  False  False\n",
       "2     True  False  False\n",
       "3     True  False  False\n",
       "4     True  False  False\n",
       "..     ...    ...    ...\n",
       "145  False  False   True\n",
       "146  False  False   True\n",
       "147  False  False   True\n",
       "148  False  False   True\n",
       "149  False  False   True\n",
       "\n",
       "[150 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffce350f-778a-484d-8f8b-9f4a97ce157f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "299ff4f9-5f15-4c91-a068-26b7d1e1eb76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length in cm</th>\n",
       "      <th>sepal width in cm</th>\n",
       "      <th>petal length in cm</th>\n",
       "      <th>petal width in cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>6.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length in cm  sepal width in cm  petal length in cm  \\\n",
       "0                   5.1                3.5                 1.4   \n",
       "55                  5.7                2.8                 4.5   \n",
       "82                  5.8                2.7                 3.9   \n",
       "75                  6.6                3.0                 4.4   \n",
       "47                  4.6                3.2                 1.4   \n",
       "..                  ...                ...                 ...   \n",
       "121                 5.6                2.8                 4.9   \n",
       "89                  5.5                2.5                 4.0   \n",
       "8                   4.4                2.9                 1.4   \n",
       "137                 6.4                3.1                 5.5   \n",
       "124                 6.7                3.3                 5.7   \n",
       "\n",
       "     petal width in cm  \n",
       "0                  0.2  \n",
       "55                 1.3  \n",
       "82                 1.2  \n",
       "75                 1.4  \n",
       "47                 0.2  \n",
       "..                 ...  \n",
       "121                2.0  \n",
       "89                 1.3  \n",
       "8                  0.2  \n",
       "137                1.8  \n",
       "124                2.1  \n",
       "\n",
       "[107 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "125ad667-da80-4813-9e1a-f6b92c711577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1      2      3\n",
       "0     True  False  False\n",
       "55   False   True  False\n",
       "82   False   True  False\n",
       "75   False   True  False\n",
       "47    True  False  False\n",
       "..     ...    ...    ...\n",
       "121  False  False   True\n",
       "89   False   True  False\n",
       "8     True  False  False\n",
       "137  False  False   True\n",
       "124  False  False   True\n",
       "\n",
       "[107 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cd11d55-7b2d-48d5-986e-0fb1ca3fe8e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length in cm</th>\n",
       "      <th>sepal width in cm</th>\n",
       "      <th>petal length in cm</th>\n",
       "      <th>petal width in cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>7.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>6.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length in cm  sepal width in cm  petal length in cm  \\\n",
       "57                  4.9                2.4                 3.3   \n",
       "52                  6.9                3.1                 4.9   \n",
       "107                 7.3                2.9                 6.3   \n",
       "20                  5.4                3.4                 1.7   \n",
       "138                 6.0                3.0                 4.8   \n",
       "39                  5.1                3.4                 1.5   \n",
       "91                  6.1                3.0                 4.6   \n",
       "65                  6.7                3.1                 4.4   \n",
       "53                  5.5                2.3                 4.0   \n",
       "132                 6.4                2.8                 5.6   \n",
       "38                  4.4                3.0                 1.3   \n",
       "111                 6.4                2.7                 5.3   \n",
       "86                  6.7                3.1                 4.7   \n",
       "45                  4.8                3.0                 1.4   \n",
       "63                  6.1                2.9                 4.7   \n",
       "93                  5.0                2.3                 3.3   \n",
       "72                  6.3                2.5                 4.9   \n",
       "14                  5.8                4.0                 1.2   \n",
       "76                  6.8                2.8                 4.8   \n",
       "139                 6.9                3.1                 5.4   \n",
       "\n",
       "     petal width in cm  \n",
       "57                 1.0  \n",
       "52                 1.5  \n",
       "107                1.8  \n",
       "20                 0.2  \n",
       "138                1.8  \n",
       "39                 0.2  \n",
       "91                 1.4  \n",
       "65                 1.4  \n",
       "53                 1.3  \n",
       "132                2.2  \n",
       "38                 0.2  \n",
       "111                1.9  \n",
       "86                 1.5  \n",
       "45                 0.3  \n",
       "63                 1.4  \n",
       "93                 1.0  \n",
       "72                 1.5  \n",
       "14                 0.2  \n",
       "76                 1.4  \n",
       "139                2.1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02406a49-1ac6-4dbf-b88a-ebe286397c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         1      2      3\n",
       "57   False   True  False\n",
       "52   False   True  False\n",
       "107  False  False   True\n",
       "20    True  False  False\n",
       "138  False  False   True\n",
       "39    True  False  False\n",
       "91   False   True  False\n",
       "65   False   True  False\n",
       "53   False   True  False\n",
       "132  False  False   True\n",
       "38    True  False  False\n",
       "111  False  False   True\n",
       "86   False   True  False\n",
       "45    True  False  False\n",
       "63   False   True  False\n",
       "93   False   True  False\n",
       "72   False   True  False\n",
       "14    True  False  False\n",
       "76   False   True  False\n",
       "139  False  False   True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9a84be4-c030-4c31-b08c-41c20203ba77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length in cm</th>\n",
       "      <th>sepal width in cm</th>\n",
       "      <th>petal length in cm</th>\n",
       "      <th>petal width in cm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>6.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>5.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length in cm  sepal width in cm  petal length in cm  \\\n",
       "101                 5.8                2.7                 5.1   \n",
       "83                  6.0                2.7                 5.1   \n",
       "2                   4.7                3.2                 1.3   \n",
       "49                  5.0                3.3                 1.4   \n",
       "80                  5.5                2.4                 3.8   \n",
       "69                  5.6                2.5                 3.9   \n",
       "118                 7.7                2.6                 6.9   \n",
       "62                  6.0                2.2                 4.0   \n",
       "85                  6.0                3.4                 4.5   \n",
       "144                 6.7                3.3                 5.7   \n",
       "48                  5.3                3.7                 1.5   \n",
       "108                 6.7                2.5                 5.8   \n",
       "123                 6.3                2.7                 4.9   \n",
       "32                  5.2                4.1                 1.5   \n",
       "110                 6.5                3.2                 5.1   \n",
       "146                 6.3                2.5                 5.0   \n",
       "145                 6.7                3.0                 5.2   \n",
       "59                  5.2                2.7                 3.9   \n",
       "43                  5.0                3.5                 1.6   \n",
       "22                  4.6                3.6                 1.0   \n",
       "133                 6.3                2.8                 5.1   \n",
       "135                 7.7                3.0                 6.1   \n",
       "51                  6.4                3.2                 4.5   \n",
       "\n",
       "     petal width in cm  \n",
       "101                1.9  \n",
       "83                 1.6  \n",
       "2                  0.2  \n",
       "49                 0.2  \n",
       "80                 1.1  \n",
       "69                 1.1  \n",
       "118                2.3  \n",
       "62                 1.0  \n",
       "85                 1.6  \n",
       "144                2.5  \n",
       "48                 0.2  \n",
       "108                1.8  \n",
       "123                1.8  \n",
       "32                 0.1  \n",
       "110                2.0  \n",
       "146                1.9  \n",
       "145                2.3  \n",
       "59                 1.4  \n",
       "43                 0.6  \n",
       "22                 0.2  \n",
       "133                1.5  \n",
       "135                2.3  \n",
       "51                 1.5  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9390465-1859-4c36-9ae6-ac1b4e7a049a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         1      2      3\n",
       "101  False  False   True\n",
       "83   False   True  False\n",
       "2     True  False  False\n",
       "49    True  False  False\n",
       "80   False   True  False\n",
       "69   False   True  False\n",
       "118  False  False   True\n",
       "62   False   True  False\n",
       "85   False   True  False\n",
       "144  False  False   True\n",
       "48    True  False  False\n",
       "108  False  False   True\n",
       "123  False  False   True\n",
       "32    True  False  False\n",
       "110  False  False   True\n",
       "146  False  False   True\n",
       "145  False  False   True\n",
       "59   False   True  False\n",
       "43    True  False  False\n",
       "22    True  False  False\n",
       "133  False  False   True\n",
       "135  False  False   True\n",
       "51   False   True  False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88f5ecc9-b736-45fa-bfb8-e5a6d549230e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((107, 4), (107, 3), (20, 4), (20, 3), (23, 4), (23, 3))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac25ca4-4d73-4f33-a971-7c29764ca95c",
   "metadata": {},
   "source": [
    "## 2. Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b4778a-2904-405d-9f81-f31a800e3ce5",
   "metadata": {},
   "source": [
    "### 2.1. Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a198f3ac-e722-46ef-b6e2-46da208774a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kostas/Documents/git/Iris_classification/lib/python3.11/site-packages/keras/src/layers/core/dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-04-09 14:54:16.408241: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-09 14:54:16.409260: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │            \u001b[38;5;34m80\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">131</span> (524.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m131\u001b[0m (524.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">131</span> (524.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m131\u001b[0m (524.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(16, activation='relu', input_shape=(4,)))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63169ec6-e39b-4159-9848-6ebb327d5198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='images/model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c685b9-6df9-4b7d-b3a4-125309cfa325",
   "metadata": {},
   "source": [
    "### 2.2. Model compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfae43a2-7b8c-4b11-81fa-a6e23a8130a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', 'recall', 'precision', 'TruePositives', 'TrueNegatives', 'FalsePositives', 'FalseNegatives'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18492041-502b-4336-b98c-c4da181f2f4b",
   "metadata": {},
   "source": [
    "### 2.3. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18dba587-6043-4e27-bcc1-80d520c2f1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - FalseNegatives: 45.4000 - FalsePositives: 45.4000 - TrueNegatives: 83.8000 - TruePositives: 19.2000 - accuracy: 0.2881 - loss: 2.2469 - precision: 0.2881 - recall: 0.2881 - val_FalseNegatives: 15.0000 - val_FalsePositives: 15.0000 - val_TrueNegatives: 25.0000 - val_TruePositives: 5.0000 - val_accuracy: 0.2500 - val_loss: 2.2179 - val_precision: 0.2500 - val_recall: 0.2500\n",
      "Epoch 2/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 40.9000 - FalsePositives: 36.0000 - TrueNegatives: 93.2000 - TruePositives: 23.7000 - accuracy: 0.3873 - loss: 1.5181 - precision: 0.4072 - recall: 0.3873 - val_FalseNegatives: 15.0000 - val_FalsePositives: 11.0000 - val_TrueNegatives: 29.0000 - val_TruePositives: 5.0000 - val_accuracy: 0.2500 - val_loss: 1.7093 - val_precision: 0.3125 - val_recall: 0.2500\n",
      "Epoch 3/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 43.4000 - FalsePositives: 23.9000 - TrueNegatives: 105.3000 - TruePositives: 21.2000 - accuracy: 0.3318 - loss: 1.3228 - precision: 0.4864 - recall: 0.3318 - val_FalseNegatives: 15.0000 - val_FalsePositives: 11.0000 - val_TrueNegatives: 29.0000 - val_TruePositives: 5.0000 - val_accuracy: 0.2500 - val_loss: 1.3476 - val_precision: 0.3125 - val_recall: 0.2500\n",
      "Epoch 4/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 44.5000 - FalsePositives: 30.1000 - TrueNegatives: 99.1000 - TruePositives: 20.1000 - accuracy: 0.3053 - loss: 1.1448 - precision: 0.3845 - recall: 0.2997 - val_FalseNegatives: 16.0000 - val_FalsePositives: 8.0000 - val_TrueNegatives: 32.0000 - val_TruePositives: 4.0000 - val_accuracy: 0.2500 - val_loss: 1.1719 - val_precision: 0.3333 - val_recall: 0.2000\n",
      "Epoch 5/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - FalseNegatives: 50.7000 - FalsePositives: 16.1000 - TrueNegatives: 113.1000 - TruePositives: 13.9000 - accuracy: 0.3187 - loss: 1.0475 - precision: 0.4591 - recall: 0.2203 - val_FalseNegatives: 16.0000 - val_FalsePositives: 3.0000 - val_TrueNegatives: 37.0000 - val_TruePositives: 4.0000 - val_accuracy: 0.2500 - val_loss: 1.0935 - val_precision: 0.5714 - val_recall: 0.2000\n",
      "Epoch 6/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 54.8000 - FalsePositives: 4.0000 - TrueNegatives: 125.2000 - TruePositives: 9.8000 - accuracy: 0.3887 - loss: 0.9820 - precision: 0.7556 - recall: 0.1616 - val_FalseNegatives: 16.0000 - val_FalsePositives: 2.0000 - val_TrueNegatives: 38.0000 - val_TruePositives: 4.0000 - val_accuracy: 0.2500 - val_loss: 1.0456 - val_precision: 0.6667 - val_recall: 0.2000\n",
      "Epoch 7/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 52.9000 - FalsePositives: 3.2000 - TrueNegatives: 126.0000 - TruePositives: 11.7000 - accuracy: 0.3894 - loss: 0.9413 - precision: 0.7858 - recall: 0.1836 - val_FalseNegatives: 16.0000 - val_FalsePositives: 3.0000 - val_TrueNegatives: 37.0000 - val_TruePositives: 4.0000 - val_accuracy: 0.2500 - val_loss: 1.0115 - val_precision: 0.5714 - val_recall: 0.2000\n",
      "Epoch 8/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 49.3000 - FalsePositives: 3.0000 - TrueNegatives: 126.2000 - TruePositives: 15.3000 - accuracy: 0.3720 - loss: 0.8951 - precision: 0.8107 - recall: 0.2414 - val_FalseNegatives: 16.0000 - val_FalsePositives: 4.0000 - val_TrueNegatives: 36.0000 - val_TruePositives: 4.0000 - val_accuracy: 0.4500 - val_loss: 0.9811 - val_precision: 0.5000 - val_recall: 0.2000\n",
      "Epoch 9/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 49.2000 - FalsePositives: 2.8000 - TrueNegatives: 126.4000 - TruePositives: 15.4000 - accuracy: 0.6842 - loss: 0.8726 - precision: 0.8622 - recall: 0.2261 - val_FalseNegatives: 16.0000 - val_FalsePositives: 4.0000 - val_TrueNegatives: 36.0000 - val_TruePositives: 4.0000 - val_accuracy: 0.5000 - val_loss: 0.9487 - val_precision: 0.5000 - val_recall: 0.2000\n",
      "Epoch 10/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - FalseNegatives: 45.0000 - FalsePositives: 3.0000 - TrueNegatives: 126.2000 - TruePositives: 19.6000 - accuracy: 0.6794 - loss: 0.8468 - precision: 0.8272 - recall: 0.2901 - val_FalseNegatives: 15.0000 - val_FalsePositives: 4.0000 - val_TrueNegatives: 36.0000 - val_TruePositives: 5.0000 - val_accuracy: 0.5000 - val_loss: 0.9216 - val_precision: 0.5556 - val_recall: 0.2500\n",
      "Epoch 11/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 28.5000 - FalsePositives: 3.1000 - TrueNegatives: 126.1000 - TruePositives: 36.1000 - accuracy: 0.7497 - loss: 0.7634 - precision: 0.9332 - recall: 0.5907 - val_FalseNegatives: 11.0000 - val_FalsePositives: 5.0000 - val_TrueNegatives: 35.0000 - val_TruePositives: 9.0000 - val_accuracy: 0.5000 - val_loss: 0.9033 - val_precision: 0.6429 - val_recall: 0.4500\n",
      "Epoch 12/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 23.5000 - FalsePositives: 3.4000 - TrueNegatives: 125.8000 - TruePositives: 41.1000 - accuracy: 0.7181 - loss: 0.7635 - precision: 0.9219 - recall: 0.6428 - val_FalseNegatives: 10.0000 - val_FalsePositives: 4.0000 - val_TrueNegatives: 36.0000 - val_TruePositives: 10.0000 - val_accuracy: 0.5000 - val_loss: 0.8706 - val_precision: 0.7143 - val_recall: 0.5000\n",
      "Epoch 13/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 20.9000 - FalsePositives: 2.8000 - TrueNegatives: 126.4000 - TruePositives: 43.7000 - accuracy: 0.7189 - loss: 0.7121 - precision: 0.9533 - recall: 0.6788 - val_FalseNegatives: 10.0000 - val_FalsePositives: 5.0000 - val_TrueNegatives: 35.0000 - val_TruePositives: 10.0000 - val_accuracy: 0.5000 - val_loss: 0.8478 - val_precision: 0.6667 - val_recall: 0.5000\n",
      "Epoch 14/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - FalseNegatives: 19.9000 - FalsePositives: 2.4000 - TrueNegatives: 126.8000 - TruePositives: 44.7000 - accuracy: 0.8059 - loss: 0.6548 - precision: 0.9617 - recall: 0.7368 - val_FalseNegatives: 10.0000 - val_FalsePositives: 4.0000 - val_TrueNegatives: 36.0000 - val_TruePositives: 10.0000 - val_accuracy: 0.5000 - val_loss: 0.8244 - val_precision: 0.7143 - val_recall: 0.5000\n",
      "Epoch 15/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - FalseNegatives: 23.6000 - FalsePositives: 2.8000 - TrueNegatives: 126.4000 - TruePositives: 41.0000 - accuracy: 0.7198 - loss: 0.6876 - precision: 0.9402 - recall: 0.6407 - val_FalseNegatives: 11.0000 - val_FalsePositives: 3.0000 - val_TrueNegatives: 37.0000 - val_TruePositives: 9.0000 - val_accuracy: 0.5500 - val_loss: 0.7866 - val_precision: 0.7500 - val_recall: 0.4500\n",
      "Epoch 16/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 20.5000 - FalsePositives: 2.4000 - TrueNegatives: 126.8000 - TruePositives: 44.1000 - accuracy: 0.7829 - loss: 0.6432 - precision: 0.9593 - recall: 0.6911 - val_FalseNegatives: 10.0000 - val_FalsePositives: 4.0000 - val_TrueNegatives: 36.0000 - val_TruePositives: 10.0000 - val_accuracy: 0.5500 - val_loss: 0.7742 - val_precision: 0.7143 - val_recall: 0.5000\n",
      "Epoch 17/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - FalseNegatives: 21.5000 - FalsePositives: 1.9000 - TrueNegatives: 127.3000 - TruePositives: 43.1000 - accuracy: 0.7586 - loss: 0.6255 - precision: 0.9689 - recall: 0.6801 - val_FalseNegatives: 10.0000 - val_FalsePositives: 3.0000 - val_TrueNegatives: 37.0000 - val_TruePositives: 10.0000 - val_accuracy: 0.5500 - val_loss: 0.7535 - val_precision: 0.7692 - val_recall: 0.5000\n",
      "Epoch 18/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 22.0000 - FalsePositives: 1.8000 - TrueNegatives: 127.4000 - TruePositives: 42.6000 - accuracy: 0.7511 - loss: 0.6286 - precision: 0.9727 - recall: 0.6526 - val_FalseNegatives: 10.0000 - val_FalsePositives: 4.0000 - val_TrueNegatives: 36.0000 - val_TruePositives: 10.0000 - val_accuracy: 0.5500 - val_loss: 0.7376 - val_precision: 0.7143 - val_recall: 0.5000\n",
      "Epoch 19/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 20.2000 - FalsePositives: 2.1000 - TrueNegatives: 127.1000 - TruePositives: 44.4000 - accuracy: 0.8145 - loss: 0.5879 - precision: 0.9580 - recall: 0.7095 - val_FalseNegatives: 10.0000 - val_FalsePositives: 4.0000 - val_TrueNegatives: 36.0000 - val_TruePositives: 10.0000 - val_accuracy: 0.5500 - val_loss: 0.7304 - val_precision: 0.7143 - val_recall: 0.5000\n",
      "Epoch 20/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - FalseNegatives: 22.0000 - FalsePositives: 3.0000 - TrueNegatives: 126.2000 - TruePositives: 42.6000 - accuracy: 0.7334 - loss: 0.6171 - precision: 0.9089 - recall: 0.6332 - val_FalseNegatives: 10.0000 - val_FalsePositives: 4.0000 - val_TrueNegatives: 36.0000 - val_TruePositives: 10.0000 - val_accuracy: 0.6000 - val_loss: 0.7071 - val_precision: 0.7143 - val_recall: 0.5000\n",
      "Epoch 21/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 25.4000 - FalsePositives: 3.4000 - TrueNegatives: 125.8000 - TruePositives: 39.2000 - accuracy: 0.7688 - loss: 0.6156 - precision: 0.9023 - recall: 0.5823 - val_FalseNegatives: 10.0000 - val_FalsePositives: 3.0000 - val_TrueNegatives: 37.0000 - val_TruePositives: 10.0000 - val_accuracy: 0.6500 - val_loss: 0.6846 - val_precision: 0.7692 - val_recall: 0.5000\n",
      "Epoch 22/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 22.7000 - FalsePositives: 2.6000 - TrueNegatives: 126.6000 - TruePositives: 41.9000 - accuracy: 0.7792 - loss: 0.5657 - precision: 0.9533 - recall: 0.6339 - val_FalseNegatives: 10.0000 - val_FalsePositives: 4.0000 - val_TrueNegatives: 36.0000 - val_TruePositives: 10.0000 - val_accuracy: 0.5500 - val_loss: 0.6908 - val_precision: 0.7143 - val_recall: 0.5000\n",
      "Epoch 23/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 20.6000 - FalsePositives: 2.7000 - TrueNegatives: 126.5000 - TruePositives: 44.0000 - accuracy: 0.7806 - loss: 0.5420 - precision: 0.9382 - recall: 0.6814 - val_FalseNegatives: 10.0000 - val_FalsePositives: 4.0000 - val_TrueNegatives: 36.0000 - val_TruePositives: 10.0000 - val_accuracy: 0.5500 - val_loss: 0.6810 - val_precision: 0.7143 - val_recall: 0.5000\n",
      "Epoch 24/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 19.7000 - FalsePositives: 2.7000 - TrueNegatives: 126.5000 - TruePositives: 44.9000 - accuracy: 0.8048 - loss: 0.5309 - precision: 0.9346 - recall: 0.7015 - val_FalseNegatives: 10.0000 - val_FalsePositives: 4.0000 - val_TrueNegatives: 36.0000 - val_TruePositives: 10.0000 - val_accuracy: 0.6000 - val_loss: 0.6702 - val_precision: 0.7143 - val_recall: 0.5000\n",
      "Epoch 25/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - FalseNegatives: 21.4000 - FalsePositives: 2.8000 - TrueNegatives: 126.4000 - TruePositives: 43.2000 - accuracy: 0.7651 - loss: 0.5504 - precision: 0.9466 - recall: 0.6753 - val_FalseNegatives: 10.0000 - val_FalsePositives: 4.0000 - val_TrueNegatives: 36.0000 - val_TruePositives: 10.0000 - val_accuracy: 0.6500 - val_loss: 0.6485 - val_precision: 0.7143 - val_recall: 0.5000\n",
      "Epoch 26/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 20.0000 - FalsePositives: 2.7000 - TrueNegatives: 126.5000 - TruePositives: 44.6000 - accuracy: 0.8134 - loss: 0.5207 - precision: 0.9268 - recall: 0.6916 - val_FalseNegatives: 10.0000 - val_FalsePositives: 4.0000 - val_TrueNegatives: 36.0000 - val_TruePositives: 10.0000 - val_accuracy: 0.6500 - val_loss: 0.6410 - val_precision: 0.7143 - val_recall: 0.5000\n",
      "Epoch 27/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - FalseNegatives: 20.2000 - FalsePositives: 1.4000 - TrueNegatives: 127.8000 - TruePositives: 44.4000 - accuracy: 0.8540 - loss: 0.4925 - precision: 0.9804 - recall: 0.6806 - val_FalseNegatives: 10.0000 - val_FalsePositives: 4.0000 - val_TrueNegatives: 36.0000 - val_TruePositives: 10.0000 - val_accuracy: 0.7000 - val_loss: 0.6306 - val_precision: 0.7143 - val_recall: 0.5000\n",
      "Epoch 28/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 20.0000 - FalsePositives: 1.6000 - TrueNegatives: 127.6000 - TruePositives: 44.6000 - accuracy: 0.8567 - loss: 0.4796 - precision: 0.9766 - recall: 0.6993 - val_FalseNegatives: 10.0000 - val_FalsePositives: 4.0000 - val_TrueNegatives: 36.0000 - val_TruePositives: 10.0000 - val_accuracy: 0.7000 - val_loss: 0.6204 - val_precision: 0.7143 - val_recall: 0.5000\n",
      "Epoch 29/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 20.2000 - FalsePositives: 2.8000 - TrueNegatives: 126.4000 - TruePositives: 44.4000 - accuracy: 0.8447 - loss: 0.4929 - precision: 0.9456 - recall: 0.6854 - val_FalseNegatives: 10.0000 - val_FalsePositives: 3.0000 - val_TrueNegatives: 37.0000 - val_TruePositives: 10.0000 - val_accuracy: 0.7000 - val_loss: 0.6086 - val_precision: 0.7692 - val_recall: 0.5000\n",
      "Epoch 30/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 21.1000 - FalsePositives: 3.2000 - TrueNegatives: 126.0000 - TruePositives: 43.5000 - accuracy: 0.8742 - loss: 0.5342 - precision: 0.9078 - recall: 0.6425 - val_FalseNegatives: 10.0000 - val_FalsePositives: 3.0000 - val_TrueNegatives: 37.0000 - val_TruePositives: 10.0000 - val_accuracy: 0.7000 - val_loss: 0.5958 - val_precision: 0.7692 - val_recall: 0.5000\n",
      "Epoch 31/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 17.0000 - FalsePositives: 2.4000 - TrueNegatives: 126.8000 - TruePositives: 47.6000 - accuracy: 0.8689 - loss: 0.4858 - precision: 0.9565 - recall: 0.7216 - val_FalseNegatives: 10.0000 - val_FalsePositives: 5.0000 - val_TrueNegatives: 35.0000 - val_TruePositives: 10.0000 - val_accuracy: 0.6500 - val_loss: 0.6094 - val_precision: 0.6667 - val_recall: 0.5000\n",
      "Epoch 32/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 19.2000 - FalsePositives: 2.3000 - TrueNegatives: 126.9000 - TruePositives: 45.4000 - accuracy: 0.8111 - loss: 0.5095 - precision: 0.9571 - recall: 0.6715 - val_FalseNegatives: 10.0000 - val_FalsePositives: 3.0000 - val_TrueNegatives: 37.0000 - val_TruePositives: 10.0000 - val_accuracy: 0.7000 - val_loss: 0.5865 - val_precision: 0.7692 - val_recall: 0.5000\n",
      "Epoch 33/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 14.5000 - FalsePositives: 1.7000 - TrueNegatives: 127.5000 - TruePositives: 50.1000 - accuracy: 0.8719 - loss: 0.4392 - precision: 0.9622 - recall: 0.7876 - val_FalseNegatives: 10.0000 - val_FalsePositives: 4.0000 - val_TrueNegatives: 36.0000 - val_TruePositives: 10.0000 - val_accuracy: 0.7000 - val_loss: 0.5863 - val_precision: 0.7143 - val_recall: 0.5000\n",
      "Epoch 34/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 15.7000 - FalsePositives: 1.6000 - TrueNegatives: 127.6000 - TruePositives: 48.9000 - accuracy: 0.8926 - loss: 0.4432 - precision: 0.9764 - recall: 0.7573 - val_FalseNegatives: 9.0000 - val_FalsePositives: 3.0000 - val_TrueNegatives: 37.0000 - val_TruePositives: 11.0000 - val_accuracy: 0.7500 - val_loss: 0.5667 - val_precision: 0.7857 - val_recall: 0.5500\n",
      "Epoch 35/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - FalseNegatives: 15.5000 - FalsePositives: 3.3000 - TrueNegatives: 125.9000 - TruePositives: 49.1000 - accuracy: 0.9009 - loss: 0.4464 - precision: 0.9208 - recall: 0.7547 - val_FalseNegatives: 8.0000 - val_FalsePositives: 3.0000 - val_TrueNegatives: 37.0000 - val_TruePositives: 12.0000 - val_accuracy: 0.8000 - val_loss: 0.5527 - val_precision: 0.8000 - val_recall: 0.6000\n",
      "Epoch 36/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - FalseNegatives: 14.5000 - FalsePositives: 2.0000 - TrueNegatives: 127.2000 - TruePositives: 50.1000 - accuracy: 0.9474 - loss: 0.4058 - precision: 0.9568 - recall: 0.7754 - val_FalseNegatives: 9.0000 - val_FalsePositives: 3.0000 - val_TrueNegatives: 37.0000 - val_TruePositives: 11.0000 - val_accuracy: 0.7500 - val_loss: 0.5578 - val_precision: 0.7857 - val_recall: 0.5500\n",
      "Epoch 37/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 13.4000 - FalsePositives: 2.5000 - TrueNegatives: 126.7000 - TruePositives: 51.2000 - accuracy: 0.9197 - loss: 0.4211 - precision: 0.9618 - recall: 0.8095 - val_FalseNegatives: 9.0000 - val_FalsePositives: 3.0000 - val_TrueNegatives: 37.0000 - val_TruePositives: 11.0000 - val_accuracy: 0.7500 - val_loss: 0.5569 - val_precision: 0.7857 - val_recall: 0.5500\n",
      "Epoch 38/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 14.0000 - FalsePositives: 2.4000 - TrueNegatives: 126.8000 - TruePositives: 50.6000 - accuracy: 0.9036 - loss: 0.4120 - precision: 0.9517 - recall: 0.7819 - val_FalseNegatives: 8.0000 - val_FalsePositives: 3.0000 - val_TrueNegatives: 37.0000 - val_TruePositives: 12.0000 - val_accuracy: 0.8000 - val_loss: 0.5386 - val_precision: 0.8000 - val_recall: 0.6000\n",
      "Epoch 39/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 11.0000 - FalsePositives: 2.2000 - TrueNegatives: 127.0000 - TruePositives: 53.6000 - accuracy: 0.9633 - loss: 0.4065 - precision: 0.9656 - recall: 0.8485 - val_FalseNegatives: 8.0000 - val_FalsePositives: 3.0000 - val_TrueNegatives: 37.0000 - val_TruePositives: 12.0000 - val_accuracy: 0.8500 - val_loss: 0.5268 - val_precision: 0.8000 - val_recall: 0.6000\n",
      "Epoch 40/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 12.0000 - FalsePositives: 3.0000 - TrueNegatives: 126.2000 - TruePositives: 52.6000 - accuracy: 0.8863 - loss: 0.4333 - precision: 0.9369 - recall: 0.7915 - val_FalseNegatives: 7.0000 - val_FalsePositives: 3.0000 - val_TrueNegatives: 37.0000 - val_TruePositives: 13.0000 - val_accuracy: 0.8500 - val_loss: 0.5153 - val_precision: 0.8125 - val_recall: 0.6500\n",
      "Epoch 41/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 10.2000 - FalsePositives: 3.8000 - TrueNegatives: 125.4000 - TruePositives: 54.4000 - accuracy: 0.9378 - loss: 0.4237 - precision: 0.9405 - recall: 0.8395 - val_FalseNegatives: 7.0000 - val_FalsePositives: 3.0000 - val_TrueNegatives: 37.0000 - val_TruePositives: 13.0000 - val_accuracy: 0.8500 - val_loss: 0.5153 - val_precision: 0.8125 - val_recall: 0.6500\n",
      "Epoch 42/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 10.1000 - FalsePositives: 2.4000 - TrueNegatives: 126.8000 - TruePositives: 54.5000 - accuracy: 0.9394 - loss: 0.3964 - precision: 0.9489 - recall: 0.8415 - val_FalseNegatives: 7.0000 - val_FalsePositives: 3.0000 - val_TrueNegatives: 37.0000 - val_TruePositives: 13.0000 - val_accuracy: 0.8000 - val_loss: 0.5216 - val_precision: 0.8125 - val_recall: 0.6500\n",
      "Epoch 43/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - FalseNegatives: 10.1000 - FalsePositives: 3.1000 - TrueNegatives: 126.1000 - TruePositives: 54.5000 - accuracy: 0.9346 - loss: 0.3885 - precision: 0.9513 - recall: 0.8778 - val_FalseNegatives: 9.0000 - val_FalsePositives: 4.0000 - val_TrueNegatives: 36.0000 - val_TruePositives: 11.0000 - val_accuracy: 0.7500 - val_loss: 0.5301 - val_precision: 0.7333 - val_recall: 0.5500\n",
      "Epoch 44/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 10.5000 - FalsePositives: 3.1000 - TrueNegatives: 126.1000 - TruePositives: 54.1000 - accuracy: 0.9139 - loss: 0.4067 - precision: 0.9428 - recall: 0.8294 - val_FalseNegatives: 3.0000 - val_FalsePositives: 3.0000 - val_TrueNegatives: 37.0000 - val_TruePositives: 17.0000 - val_accuracy: 0.8500 - val_loss: 0.4937 - val_precision: 0.8500 - val_recall: 0.8500\n",
      "Epoch 45/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 7.2000 - FalsePositives: 3.0000 - TrueNegatives: 126.2000 - TruePositives: 57.4000 - accuracy: 0.9475 - loss: 0.3915 - precision: 0.9533 - recall: 0.8836 - val_FalseNegatives: 3.0000 - val_FalsePositives: 3.0000 - val_TrueNegatives: 37.0000 - val_TruePositives: 17.0000 - val_accuracy: 0.8500 - val_loss: 0.4885 - val_precision: 0.8500 - val_recall: 0.8500\n",
      "Epoch 46/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 7.1000 - FalsePositives: 1.6000 - TrueNegatives: 127.6000 - TruePositives: 57.5000 - accuracy: 0.9387 - loss: 0.3898 - precision: 0.9810 - recall: 0.8954 - val_FalseNegatives: 5.0000 - val_FalsePositives: 3.0000 - val_TrueNegatives: 37.0000 - val_TruePositives: 15.0000 - val_accuracy: 0.8500 - val_loss: 0.4928 - val_precision: 0.8333 - val_recall: 0.7500\n",
      "Epoch 47/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - FalseNegatives: 7.4000 - FalsePositives: 3.1000 - TrueNegatives: 126.1000 - TruePositives: 57.2000 - accuracy: 0.9096 - loss: 0.4010 - precision: 0.9298 - recall: 0.8757 - val_FalseNegatives: 5.0000 - val_FalsePositives: 3.0000 - val_TrueNegatives: 37.0000 - val_TruePositives: 15.0000 - val_accuracy: 0.8500 - val_loss: 0.4911 - val_precision: 0.8333 - val_recall: 0.7500\n",
      "Epoch 48/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 7.7000 - FalsePositives: 2.5000 - TrueNegatives: 126.7000 - TruePositives: 56.9000 - accuracy: 0.9519 - loss: 0.3709 - precision: 0.9611 - recall: 0.8775 - val_FalseNegatives: 4.0000 - val_FalsePositives: 3.0000 - val_TrueNegatives: 37.0000 - val_TruePositives: 16.0000 - val_accuracy: 0.8500 - val_loss: 0.4817 - val_precision: 0.8421 - val_recall: 0.8000\n",
      "Epoch 49/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 5.8000 - FalsePositives: 2.0000 - TrueNegatives: 127.2000 - TruePositives: 58.8000 - accuracy: 0.9562 - loss: 0.3355 - precision: 0.9761 - recall: 0.9238 - val_FalseNegatives: 3.0000 - val_FalsePositives: 3.0000 - val_TrueNegatives: 37.0000 - val_TruePositives: 17.0000 - val_accuracy: 0.8500 - val_loss: 0.4750 - val_precision: 0.8500 - val_recall: 0.8500\n",
      "Epoch 50/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 6.7000 - FalsePositives: 3.0000 - TrueNegatives: 126.2000 - TruePositives: 57.9000 - accuracy: 0.9566 - loss: 0.3814 - precision: 0.9531 - recall: 0.8835 - val_FalseNegatives: 3.0000 - val_FalsePositives: 2.0000 - val_TrueNegatives: 38.0000 - val_TruePositives: 17.0000 - val_accuracy: 0.9000 - val_loss: 0.4559 - val_precision: 0.8947 - val_recall: 0.8500\n",
      "Epoch 51/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - FalseNegatives: 5.3000 - FalsePositives: 4.2000 - TrueNegatives: 125.0000 - TruePositives: 59.3000 - accuracy: 0.9266 - loss: 0.3986 - precision: 0.9329 - recall: 0.9211 - val_FalseNegatives: 2.0000 - val_FalsePositives: 2.0000 - val_TrueNegatives: 38.0000 - val_TruePositives: 18.0000 - val_accuracy: 0.9000 - val_loss: 0.4453 - val_precision: 0.9000 - val_recall: 0.9000\n",
      "Epoch 52/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 4.2000 - FalsePositives: 2.8000 - TrueNegatives: 126.4000 - TruePositives: 60.4000 - accuracy: 0.9561 - loss: 0.3561 - precision: 0.9645 - recall: 0.9487 - val_FalseNegatives: 3.0000 - val_FalsePositives: 3.0000 - val_TrueNegatives: 37.0000 - val_TruePositives: 17.0000 - val_accuracy: 0.8500 - val_loss: 0.4694 - val_precision: 0.8500 - val_recall: 0.8500\n",
      "Epoch 53/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 4.7000 - FalsePositives: 2.4000 - TrueNegatives: 126.8000 - TruePositives: 59.9000 - accuracy: 0.9615 - loss: 0.3058 - precision: 0.9676 - recall: 0.9420 - val_FalseNegatives: 3.0000 - val_FalsePositives: 3.0000 - val_TrueNegatives: 37.0000 - val_TruePositives: 17.0000 - val_accuracy: 0.8500 - val_loss: 0.4587 - val_precision: 0.8500 - val_recall: 0.8500\n",
      "Epoch 54/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - FalseNegatives: 6.1000 - FalsePositives: 2.7000 - TrueNegatives: 126.5000 - TruePositives: 58.5000 - accuracy: 0.9475 - loss: 0.3453 - precision: 0.9586 - recall: 0.9121 - val_FalseNegatives: 3.0000 - val_FalsePositives: 2.0000 - val_TrueNegatives: 38.0000 - val_TruePositives: 17.0000 - val_accuracy: 0.8500 - val_loss: 0.4503 - val_precision: 0.8947 - val_recall: 0.8500\n",
      "Epoch 55/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - FalseNegatives: 4.6000 - FalsePositives: 2.8000 - TrueNegatives: 126.4000 - TruePositives: 60.0000 - accuracy: 0.9603 - loss: 0.3218 - precision: 0.9591 - recall: 0.9344 - val_FalseNegatives: 3.0000 - val_FalsePositives: 2.0000 - val_TrueNegatives: 38.0000 - val_TruePositives: 17.0000 - val_accuracy: 0.9000 - val_loss: 0.4385 - val_precision: 0.8947 - val_recall: 0.8500\n",
      "Epoch 56/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - FalseNegatives: 3.8000 - FalsePositives: 2.7000 - TrueNegatives: 126.5000 - TruePositives: 60.8000 - accuracy: 0.9586 - loss: 0.3315 - precision: 0.9609 - recall: 0.9466 - val_FalseNegatives: 2.0000 - val_FalsePositives: 2.0000 - val_TrueNegatives: 38.0000 - val_TruePositives: 18.0000 - val_accuracy: 0.9000 - val_loss: 0.4317 - val_precision: 0.9000 - val_recall: 0.9000\n",
      "Epoch 57/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 5.4000 - FalsePositives: 3.6000 - TrueNegatives: 125.6000 - TruePositives: 59.2000 - accuracy: 0.9282 - loss: 0.3716 - precision: 0.9420 - recall: 0.9120 - val_FalseNegatives: 3.0000 - val_FalsePositives: 2.0000 - val_TrueNegatives: 38.0000 - val_TruePositives: 17.0000 - val_accuracy: 0.9000 - val_loss: 0.4312 - val_precision: 0.8947 - val_recall: 0.8500\n",
      "Epoch 58/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - FalseNegatives: 3.1000 - FalsePositives: 2.3000 - TrueNegatives: 126.9000 - TruePositives: 61.5000 - accuracy: 0.9618 - loss: 0.3061 - precision: 0.9735 - recall: 0.9618 - val_FalseNegatives: 3.0000 - val_FalsePositives: 2.0000 - val_TrueNegatives: 38.0000 - val_TruePositives: 17.0000 - val_accuracy: 0.9000 - val_loss: 0.4322 - val_precision: 0.8947 - val_recall: 0.8500\n",
      "Epoch 59/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - FalseNegatives: 5.9000 - FalsePositives: 4.4000 - TrueNegatives: 124.8000 - TruePositives: 58.7000 - accuracy: 0.8901 - loss: 0.3585 - precision: 0.9170 - recall: 0.8901 - val_FalseNegatives: 2.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 18.0000 - val_accuracy: 0.9000 - val_loss: 0.4030 - val_precision: 0.9474 - val_recall: 0.9000\n",
      "Epoch 60/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 5.1000 - FalsePositives: 4.3000 - TrueNegatives: 124.9000 - TruePositives: 59.5000 - accuracy: 0.9264 - loss: 0.3123 - precision: 0.9255 - recall: 0.9143 - val_FalseNegatives: 2.0000 - val_FalsePositives: 2.0000 - val_TrueNegatives: 38.0000 - val_TruePositives: 18.0000 - val_accuracy: 0.9000 - val_loss: 0.4133 - val_precision: 0.9000 - val_recall: 0.9000\n",
      "Epoch 61/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 2.6000 - FalsePositives: 2.3000 - TrueNegatives: 126.9000 - TruePositives: 62.0000 - accuracy: 0.9587 - loss: 0.3349 - precision: 0.9586 - recall: 0.9558 - val_FalseNegatives: 3.0000 - val_FalsePositives: 3.0000 - val_TrueNegatives: 37.0000 - val_TruePositives: 17.0000 - val_accuracy: 0.8500 - val_loss: 0.4358 - val_precision: 0.8500 - val_recall: 0.8500\n",
      "Epoch 62/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 4.3000 - FalsePositives: 3.8000 - TrueNegatives: 125.4000 - TruePositives: 60.3000 - accuracy: 0.9455 - loss: 0.3083 - precision: 0.9452 - recall: 0.9400 - val_FalseNegatives: 2.0000 - val_FalsePositives: 2.0000 - val_TrueNegatives: 38.0000 - val_TruePositives: 18.0000 - val_accuracy: 0.9000 - val_loss: 0.4167 - val_precision: 0.9000 - val_recall: 0.9000\n",
      "Epoch 63/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 4.3000 - FalsePositives: 2.8000 - TrueNegatives: 126.4000 - TruePositives: 60.3000 - accuracy: 0.9344 - loss: 0.2782 - precision: 0.9565 - recall: 0.9344 - val_FalseNegatives: 2.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 18.0000 - val_accuracy: 0.9000 - val_loss: 0.3929 - val_precision: 0.9474 - val_recall: 0.9000\n",
      "Epoch 64/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 3.7000 - FalsePositives: 2.6000 - TrueNegatives: 126.6000 - TruePositives: 60.9000 - accuracy: 0.9551 - loss: 0.3141 - precision: 0.9545 - recall: 0.9417 - val_FalseNegatives: 2.0000 - val_FalsePositives: 2.0000 - val_TrueNegatives: 38.0000 - val_TruePositives: 18.0000 - val_accuracy: 0.9000 - val_loss: 0.4005 - val_precision: 0.9000 - val_recall: 0.9000\n",
      "Epoch 65/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - FalseNegatives: 5.7000 - FalsePositives: 3.9000 - TrueNegatives: 125.3000 - TruePositives: 58.9000 - accuracy: 0.9256 - loss: 0.3549 - precision: 0.9221 - recall: 0.8891 - val_FalseNegatives: 2.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 18.0000 - val_accuracy: 0.9000 - val_loss: 0.3843 - val_precision: 0.9474 - val_recall: 0.9000\n",
      "Epoch 66/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 4.8000 - FalsePositives: 3.1000 - TrueNegatives: 126.1000 - TruePositives: 59.8000 - accuracy: 0.9483 - loss: 0.3149 - precision: 0.9489 - recall: 0.9270 - val_FalseNegatives: 2.0000 - val_FalsePositives: 2.0000 - val_TrueNegatives: 38.0000 - val_TruePositives: 18.0000 - val_accuracy: 0.9000 - val_loss: 0.3930 - val_precision: 0.9000 - val_recall: 0.9000\n",
      "Epoch 67/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - FalseNegatives: 3.0000 - FalsePositives: 3.0000 - TrueNegatives: 126.2000 - TruePositives: 61.6000 - accuracy: 0.9536 - loss: 0.3154 - precision: 0.9536 - recall: 0.9536 - val_FalseNegatives: 2.0000 - val_FalsePositives: 2.0000 - val_TrueNegatives: 38.0000 - val_TruePositives: 18.0000 - val_accuracy: 0.9000 - val_loss: 0.4024 - val_precision: 0.9000 - val_recall: 0.9000\n",
      "Epoch 68/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - FalseNegatives: 2.7000 - FalsePositives: 2.7000 - TrueNegatives: 126.5000 - TruePositives: 61.9000 - accuracy: 0.9546 - loss: 0.2796 - precision: 0.9546 - recall: 0.9546 - val_FalseNegatives: 2.0000 - val_FalsePositives: 2.0000 - val_TrueNegatives: 38.0000 - val_TruePositives: 18.0000 - val_accuracy: 0.9000 - val_loss: 0.3841 - val_precision: 0.9000 - val_recall: 0.9000\n",
      "Epoch 69/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - FalseNegatives: 3.3000 - FalsePositives: 1.8000 - TrueNegatives: 127.4000 - TruePositives: 61.3000 - accuracy: 0.9676 - loss: 0.2728 - precision: 0.9671 - recall: 0.9464 - val_FalseNegatives: 2.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 18.0000 - val_accuracy: 0.9000 - val_loss: 0.3715 - val_precision: 0.9474 - val_recall: 0.9000\n",
      "Epoch 70/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 2.4000 - FalsePositives: 2.4000 - TrueNegatives: 126.8000 - TruePositives: 62.2000 - accuracy: 0.9678 - loss: 0.2495 - precision: 0.9678 - recall: 0.9678 - val_FalseNegatives: 2.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 18.0000 - val_accuracy: 0.9500 - val_loss: 0.3653 - val_precision: 0.9474 - val_recall: 0.9000\n",
      "Epoch 71/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - FalseNegatives: 4.4000 - FalsePositives: 3.6000 - TrueNegatives: 125.6000 - TruePositives: 60.2000 - accuracy: 0.9407 - loss: 0.2763 - precision: 0.9400 - recall: 0.9287 - val_FalseNegatives: 2.0000 - val_FalsePositives: 2.0000 - val_TrueNegatives: 38.0000 - val_TruePositives: 18.0000 - val_accuracy: 0.9000 - val_loss: 0.3748 - val_precision: 0.9000 - val_recall: 0.9000\n",
      "Epoch 72/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 2.1000 - FalsePositives: 1.6000 - TrueNegatives: 127.6000 - TruePositives: 62.5000 - accuracy: 0.9793 - loss: 0.2577 - precision: 0.9810 - recall: 0.9764 - val_FalseNegatives: 2.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 18.0000 - val_accuracy: 0.9000 - val_loss: 0.3642 - val_precision: 0.9474 - val_recall: 0.9000\n",
      "Epoch 73/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 2.4000 - FalsePositives: 2.4000 - TrueNegatives: 126.8000 - TruePositives: 62.2000 - accuracy: 0.9683 - loss: 0.2562 - precision: 0.9683 - recall: 0.9683 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.3515 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 74/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - FalseNegatives: 3.1000 - FalsePositives: 3.1000 - TrueNegatives: 126.1000 - TruePositives: 61.5000 - accuracy: 0.9507 - loss: 0.2910 - precision: 0.9507 - recall: 0.9507 - val_FalseNegatives: 2.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 18.0000 - val_accuracy: 0.9500 - val_loss: 0.3520 - val_precision: 0.9474 - val_recall: 0.9000\n",
      "Epoch 75/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 3.4000 - FalsePositives: 3.4000 - TrueNegatives: 125.8000 - TruePositives: 61.2000 - accuracy: 0.9472 - loss: 0.2566 - precision: 0.9472 - recall: 0.9472 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.3429 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 76/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 3.5000 - FalsePositives: 2.2000 - TrueNegatives: 127.0000 - TruePositives: 61.1000 - accuracy: 0.9674 - loss: 0.2977 - precision: 0.9667 - recall: 0.9400 - val_FalseNegatives: 2.0000 - val_FalsePositives: 2.0000 - val_TrueNegatives: 38.0000 - val_TruePositives: 18.0000 - val_accuracy: 0.9000 - val_loss: 0.3595 - val_precision: 0.9000 - val_recall: 0.9000\n",
      "Epoch 77/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 3.7000 - FalsePositives: 2.9000 - TrueNegatives: 126.3000 - TruePositives: 60.9000 - accuracy: 0.9563 - loss: 0.2771 - precision: 0.9577 - recall: 0.9492 - val_FalseNegatives: 2.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 18.0000 - val_accuracy: 0.9500 - val_loss: 0.3451 - val_precision: 0.9474 - val_recall: 0.9000\n",
      "Epoch 78/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 2.3000 - FalsePositives: 2.0000 - TrueNegatives: 127.2000 - TruePositives: 62.3000 - accuracy: 0.9762 - loss: 0.2616 - precision: 0.9761 - recall: 0.9733 - val_FalseNegatives: 2.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 18.0000 - val_accuracy: 0.9000 - val_loss: 0.3526 - val_precision: 0.9474 - val_recall: 0.9000\n",
      "Epoch 79/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 2.1000 - FalsePositives: 2.1000 - TrueNegatives: 127.1000 - TruePositives: 62.5000 - accuracy: 0.9713 - loss: 0.2362 - precision: 0.9713 - recall: 0.9713 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.3287 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 80/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - FalseNegatives: 3.0000 - FalsePositives: 3.0000 - TrueNegatives: 126.2000 - TruePositives: 61.6000 - accuracy: 0.9547 - loss: 0.2420 - precision: 0.9547 - recall: 0.9547 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.3270 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 81/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 3.6000 - FalsePositives: 3.6000 - TrueNegatives: 125.6000 - TruePositives: 61.0000 - accuracy: 0.9362 - loss: 0.2564 - precision: 0.9362 - recall: 0.9362 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.3267 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 82/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - FalseNegatives: 3.1000 - FalsePositives: 3.1000 - TrueNegatives: 126.1000 - TruePositives: 61.5000 - accuracy: 0.9453 - loss: 0.2490 - precision: 0.9453 - recall: 0.9453 - val_FalseNegatives: 2.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 18.0000 - val_accuracy: 0.9000 - val_loss: 0.3420 - val_precision: 0.9474 - val_recall: 0.9000\n",
      "Epoch 83/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 3.0000 - FalsePositives: 2.8000 - TrueNegatives: 126.4000 - TruePositives: 61.6000 - accuracy: 0.9477 - loss: 0.2480 - precision: 0.9495 - recall: 0.9477 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.3148 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 84/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - FalseNegatives: 2.4000 - FalsePositives: 2.4000 - TrueNegatives: 126.8000 - TruePositives: 62.2000 - accuracy: 0.9655 - loss: 0.2334 - precision: 0.9655 - recall: 0.9655 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.3186 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 85/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 3.3000 - FalsePositives: 2.6000 - TrueNegatives: 126.6000 - TruePositives: 61.3000 - accuracy: 0.9617 - loss: 0.2537 - precision: 0.9613 - recall: 0.9525 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.3247 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 86/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 1.9000 - FalsePositives: 1.9000 - TrueNegatives: 127.3000 - TruePositives: 62.7000 - accuracy: 0.9765 - loss: 0.2211 - precision: 0.9765 - recall: 0.9765 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.3174 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 87/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - FalseNegatives: 2.2000 - FalsePositives: 1.4000 - TrueNegatives: 127.8000 - TruePositives: 62.4000 - accuracy: 0.9781 - loss: 0.2257 - precision: 0.9820 - recall: 0.9740 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.3010 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 88/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - FalseNegatives: 3.1000 - FalsePositives: 2.7000 - TrueNegatives: 126.5000 - TruePositives: 61.5000 - accuracy: 0.9498 - loss: 0.2217 - precision: 0.9537 - recall: 0.9498 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.3088 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 89/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 2.3000 - FalsePositives: 2.3000 - TrueNegatives: 126.9000 - TruePositives: 62.3000 - accuracy: 0.9712 - loss: 0.2298 - precision: 0.9712 - recall: 0.9712 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2979 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 90/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 2.9000 - FalsePositives: 2.9000 - TrueNegatives: 126.3000 - TruePositives: 61.7000 - accuracy: 0.9613 - loss: 0.2246 - precision: 0.9613 - recall: 0.9613 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2920 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 91/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 2.3000 - FalsePositives: 2.3000 - TrueNegatives: 126.9000 - TruePositives: 62.3000 - accuracy: 0.9712 - loss: 0.2197 - precision: 0.9712 - recall: 0.9712 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.3088 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 92/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 2.3000 - FalsePositives: 2.3000 - TrueNegatives: 126.9000 - TruePositives: 62.3000 - accuracy: 0.9616 - loss: 0.2109 - precision: 0.9616 - recall: 0.9616 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.3010 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 93/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - FalseNegatives: 2.6000 - FalsePositives: 1.9000 - TrueNegatives: 127.3000 - TruePositives: 62.0000 - accuracy: 0.9633 - loss: 0.2173 - precision: 0.9723 - recall: 0.9633 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2932 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 94/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 3.6000 - FalsePositives: 3.6000 - TrueNegatives: 125.6000 - TruePositives: 61.0000 - accuracy: 0.9317 - loss: 0.2298 - precision: 0.9317 - recall: 0.9317 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2832 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 95/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 1.6000 - FalsePositives: 1.6000 - TrueNegatives: 127.6000 - TruePositives: 63.0000 - accuracy: 0.9832 - loss: 0.2025 - precision: 0.9832 - recall: 0.9832 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2838 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 96/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - FalseNegatives: 2.3000 - FalsePositives: 2.3000 - TrueNegatives: 126.9000 - TruePositives: 62.3000 - accuracy: 0.9719 - loss: 0.2135 - precision: 0.9719 - recall: 0.9719 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2965 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 97/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 2.8000 - FalsePositives: 2.8000 - TrueNegatives: 126.4000 - TruePositives: 61.8000 - accuracy: 0.9603 - loss: 0.2116 - precision: 0.9603 - recall: 0.9603 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2834 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 98/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 1.9000 - FalsePositives: 1.9000 - TrueNegatives: 127.3000 - TruePositives: 62.7000 - accuracy: 0.9787 - loss: 0.1822 - precision: 0.9787 - recall: 0.9787 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2696 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 99/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 2.1000 - FalsePositives: 1.6000 - TrueNegatives: 127.6000 - TruePositives: 62.5000 - accuracy: 0.9735 - loss: 0.2064 - precision: 0.9788 - recall: 0.9735 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2663 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 100/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 1.6000 - FalsePositives: 1.6000 - TrueNegatives: 127.6000 - TruePositives: 63.0000 - accuracy: 0.9768 - loss: 0.1734 - precision: 0.9768 - recall: 0.9768 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2835 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 101/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 1.6000 - FalsePositives: 1.6000 - TrueNegatives: 127.6000 - TruePositives: 63.0000 - accuracy: 0.9820 - loss: 0.2030 - precision: 0.9820 - recall: 0.9820 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2854 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 102/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - FalseNegatives: 1.6000 - FalsePositives: 1.6000 - TrueNegatives: 127.6000 - TruePositives: 63.0000 - accuracy: 0.9768 - loss: 0.1938 - precision: 0.9768 - recall: 0.9768 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2698 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 103/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - FalseNegatives: 2.1000 - FalsePositives: 2.1000 - TrueNegatives: 127.1000 - TruePositives: 62.5000 - accuracy: 0.9761 - loss: 0.1841 - precision: 0.9761 - recall: 0.9761 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2570 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 104/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 2.0000 - FalsePositives: 2.0000 - TrueNegatives: 127.2000 - TruePositives: 62.6000 - accuracy: 0.9616 - loss: 0.1825 - precision: 0.9616 - recall: 0.9616 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2537 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 105/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - FalseNegatives: 2.1000 - FalsePositives: 2.1000 - TrueNegatives: 127.1000 - TruePositives: 62.5000 - accuracy: 0.9621 - loss: 0.1835 - precision: 0.9621 - recall: 0.9621 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2577 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 106/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 0.9000 - FalsePositives: 0.9000 - TrueNegatives: 128.3000 - TruePositives: 63.7000 - accuracy: 0.9899 - loss: 0.2037 - precision: 0.9899 - recall: 0.9899 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2696 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 107/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - FalseNegatives: 1.3000 - FalsePositives: 1.3000 - TrueNegatives: 127.9000 - TruePositives: 63.3000 - accuracy: 0.9858 - loss: 0.1662 - precision: 0.9858 - recall: 0.9858 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2561 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 108/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - FalseNegatives: 0.7000 - FalsePositives: 0.7000 - TrueNegatives: 128.5000 - TruePositives: 63.9000 - accuracy: 0.9926 - loss: 0.2153 - precision: 0.9926 - recall: 0.9926 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2514 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 109/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - FalseNegatives: 2.1000 - FalsePositives: 1.4000 - TrueNegatives: 127.8000 - TruePositives: 62.5000 - accuracy: 0.9746 - loss: 0.1961 - precision: 0.9836 - recall: 0.9746 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2418 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 110/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 1.7000 - FalsePositives: 1.7000 - TrueNegatives: 127.5000 - TruePositives: 62.9000 - accuracy: 0.9784 - loss: 0.1615 - precision: 0.9784 - recall: 0.9784 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2510 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 111/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 1.8000 - FalsePositives: 1.8000 - TrueNegatives: 127.4000 - TruePositives: 62.8000 - accuracy: 0.9673 - loss: 0.1762 - precision: 0.9673 - recall: 0.9673 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2524 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 112/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - FalseNegatives: 2.4000 - FalsePositives: 2.4000 - TrueNegatives: 126.8000 - TruePositives: 62.2000 - accuracy: 0.9644 - loss: 0.1887 - precision: 0.9644 - recall: 0.9644 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2508 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 113/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 1.8000 - FalsePositives: 1.3000 - TrueNegatives: 127.9000 - TruePositives: 62.8000 - accuracy: 0.9793 - loss: 0.1674 - precision: 0.9847 - recall: 0.9793 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2603 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 114/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - FalseNegatives: 2.2000 - FalsePositives: 2.2000 - TrueNegatives: 127.0000 - TruePositives: 62.4000 - accuracy: 0.9717 - loss: 0.1596 - precision: 0.9717 - recall: 0.9717 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2264 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 115/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - FalseNegatives: 2.7000 - FalsePositives: 2.7000 - TrueNegatives: 126.5000 - TruePositives: 61.9000 - accuracy: 0.9417 - loss: 0.2069 - precision: 0.9417 - recall: 0.9417 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2351 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 116/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - FalseNegatives: 2.3000 - FalsePositives: 1.5000 - TrueNegatives: 127.7000 - TruePositives: 62.3000 - accuracy: 0.9707 - loss: 0.1676 - precision: 0.9704 - recall: 0.9587 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2450 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 117/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 2.2000 - FalsePositives: 2.2000 - TrueNegatives: 127.0000 - TruePositives: 62.4000 - accuracy: 0.9594 - loss: 0.1775 - precision: 0.9594 - recall: 0.9594 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2328 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 118/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - FalseNegatives: 1.2000 - FalsePositives: 1.2000 - TrueNegatives: 128.0000 - TruePositives: 63.4000 - accuracy: 0.9736 - loss: 0.1903 - precision: 0.9736 - recall: 0.9736 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2349 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 119/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 1.6000 - FalsePositives: 1.6000 - TrueNegatives: 127.6000 - TruePositives: 63.0000 - accuracy: 0.9796 - loss: 0.1501 - precision: 0.9796 - recall: 0.9796 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2324 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 120/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 1.7000 - FalsePositives: 1.7000 - TrueNegatives: 127.5000 - TruePositives: 62.9000 - accuracy: 0.9662 - loss: 0.1900 - precision: 0.9662 - recall: 0.9662 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2266 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 121/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 1.8000 - FalsePositives: 1.8000 - TrueNegatives: 127.4000 - TruePositives: 62.8000 - accuracy: 0.9758 - loss: 0.1660 - precision: 0.9758 - recall: 0.9758 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2205 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 122/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 0.8000 - FalsePositives: 0.8000 - TrueNegatives: 128.4000 - TruePositives: 63.8000 - accuracy: 0.9916 - loss: 0.1472 - precision: 0.9916 - recall: 0.9916 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2338 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 123/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - FalseNegatives: 2.1000 - FalsePositives: 2.1000 - TrueNegatives: 127.1000 - TruePositives: 62.5000 - accuracy: 0.9647 - loss: 0.1838 - precision: 0.9647 - recall: 0.9647 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2327 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 124/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - FalseNegatives: 1.5000 - FalsePositives: 1.5000 - TrueNegatives: 127.7000 - TruePositives: 63.1000 - accuracy: 0.9817 - loss: 0.1701 - precision: 0.9817 - recall: 0.9817 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2216 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 125/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 1.5000 - FalsePositives: 1.1000 - TrueNegatives: 128.1000 - TruePositives: 63.1000 - accuracy: 0.9851 - loss: 0.1377 - precision: 0.9850 - recall: 0.9810 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2190 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 126/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 2.2000 - FalsePositives: 2.2000 - TrueNegatives: 127.0000 - TruePositives: 62.4000 - accuracy: 0.9699 - loss: 0.1427 - precision: 0.9699 - recall: 0.9699 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2101 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 127/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - FalseNegatives: 1.9000 - FalsePositives: 1.9000 - TrueNegatives: 127.3000 - TruePositives: 62.7000 - accuracy: 0.9659 - loss: 0.1603 - precision: 0.9659 - recall: 0.9659 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2137 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 128/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 1.7000 - FalsePositives: 1.7000 - TrueNegatives: 127.5000 - TruePositives: 62.9000 - accuracy: 0.9685 - loss: 0.1669 - precision: 0.9685 - recall: 0.9685 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2345 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 129/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 1.9000 - FalsePositives: 1.9000 - TrueNegatives: 127.3000 - TruePositives: 62.7000 - accuracy: 0.9746 - loss: 0.1513 - precision: 0.9746 - recall: 0.9746 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2171 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 130/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 1.5000 - FalsePositives: 1.5000 - TrueNegatives: 127.7000 - TruePositives: 63.1000 - accuracy: 0.9833 - loss: 0.1394 - precision: 0.9833 - recall: 0.9833 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2156 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 131/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - FalseNegatives: 2.4000 - FalsePositives: 2.4000 - TrueNegatives: 126.8000 - TruePositives: 62.2000 - accuracy: 0.9671 - loss: 0.1472 - precision: 0.9671 - recall: 0.9671 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2017 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 132/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 1.9000 - FalsePositives: 1.9000 - TrueNegatives: 127.3000 - TruePositives: 62.7000 - accuracy: 0.9753 - loss: 0.1542 - precision: 0.9753 - recall: 0.9753 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2049 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 133/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - FalseNegatives: 0.7000 - FalsePositives: 0.7000 - TrueNegatives: 128.5000 - TruePositives: 63.9000 - accuracy: 0.9930 - loss: 0.1529 - precision: 0.9930 - recall: 0.9930 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2186 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 134/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 2.2000 - FalsePositives: 1.7000 - TrueNegatives: 127.5000 - TruePositives: 62.4000 - accuracy: 0.9608 - loss: 0.1695 - precision: 0.9661 - recall: 0.9608 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2062 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 135/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 2.0000 - FalsePositives: 2.0000 - TrueNegatives: 127.2000 - TruePositives: 62.6000 - accuracy: 0.9705 - loss: 0.1447 - precision: 0.9705 - recall: 0.9705 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2057 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 136/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 2.4000 - FalsePositives: 1.4000 - TrueNegatives: 127.8000 - TruePositives: 62.2000 - accuracy: 0.9815 - loss: 0.1570 - precision: 0.9812 - recall: 0.9570 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2043 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 137/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - FalseNegatives: 1.0000 - FalsePositives: 1.0000 - TrueNegatives: 128.2000 - TruePositives: 63.6000 - accuracy: 0.9755 - loss: 0.1519 - precision: 0.9755 - recall: 0.9755 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2007 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 138/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - FalseNegatives: 0.4000 - FalsePositives: 0.4000 - TrueNegatives: 128.8000 - TruePositives: 64.2000 - accuracy: 0.9959 - loss: 0.1319 - precision: 0.9959 - recall: 0.9959 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2014 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 139/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - FalseNegatives: 2.1000 - FalsePositives: 1.5000 - TrueNegatives: 127.7000 - TruePositives: 62.5000 - accuracy: 0.9695 - loss: 0.1504 - precision: 0.9765 - recall: 0.9695 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1993 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 140/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 1.0000 - FalsePositives: 1.0000 - TrueNegatives: 128.2000 - TruePositives: 63.6000 - accuracy: 0.9755 - loss: 0.1783 - precision: 0.9755 - recall: 0.9755 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2002 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 141/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - FalseNegatives: 2.0000 - FalsePositives: 2.0000 - TrueNegatives: 127.2000 - TruePositives: 62.6000 - accuracy: 0.9689 - loss: 0.1326 - precision: 0.9689 - recall: 0.9689 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1999 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 142/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - FalseNegatives: 1.8000 - FalsePositives: 1.8000 - TrueNegatives: 127.4000 - TruePositives: 62.8000 - accuracy: 0.9676 - loss: 0.1455 - precision: 0.9676 - recall: 0.9676 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1936 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 143/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 1.2000 - FalsePositives: 1.2000 - TrueNegatives: 128.0000 - TruePositives: 63.4000 - accuracy: 0.9875 - loss: 0.1130 - precision: 0.9875 - recall: 0.9875 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.2031 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 144/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - FalseNegatives: 2.0000 - FalsePositives: 2.0000 - TrueNegatives: 127.2000 - TruePositives: 62.6000 - accuracy: 0.9616 - loss: 0.1626 - precision: 0.9616 - recall: 0.9616 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1859 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 145/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 1.6000 - FalsePositives: 1.6000 - TrueNegatives: 127.6000 - TruePositives: 63.0000 - accuracy: 0.9790 - loss: 0.1324 - precision: 0.9790 - recall: 0.9790 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1849 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 146/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - FalseNegatives: 0.4000 - FalsePositives: 0.4000 - TrueNegatives: 128.8000 - TruePositives: 64.2000 - accuracy: 0.9959 - loss: 0.1125 - precision: 0.9959 - recall: 0.9959 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1896 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 147/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 0.9000 - FalsePositives: 0.9000 - TrueNegatives: 128.3000 - TruePositives: 63.7000 - accuracy: 0.9904 - loss: 0.1452 - precision: 0.9904 - recall: 0.9904 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1966 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 148/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - FalseNegatives: 1.7000 - FalsePositives: 1.7000 - TrueNegatives: 127.5000 - TruePositives: 62.9000 - accuracy: 0.9681 - loss: 0.1217 - precision: 0.9681 - recall: 0.9681 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1922 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 149/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - FalseNegatives: 1.4000 - FalsePositives: 1.4000 - TrueNegatives: 127.8000 - TruePositives: 63.2000 - accuracy: 0.9844 - loss: 0.1279 - precision: 0.9844 - recall: 0.9844 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1912 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 150/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - FalseNegatives: 2.3000 - FalsePositives: 2.3000 - TrueNegatives: 126.9000 - TruePositives: 62.3000 - accuracy: 0.9653 - loss: 0.1351 - precision: 0.9653 - recall: 0.9653 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1866 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 151/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - FalseNegatives: 1.2000 - FalsePositives: 1.2000 - TrueNegatives: 128.0000 - TruePositives: 63.4000 - accuracy: 0.9853 - loss: 0.1302 - precision: 0.9853 - recall: 0.9853 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1850 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 152/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 0.8000 - FalsePositives: 0.8000 - TrueNegatives: 128.4000 - TruePositives: 63.8000 - accuracy: 0.9910 - loss: 0.1123 - precision: 0.9910 - recall: 0.9910 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1758 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 153/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 1.7000 - FalsePositives: 1.7000 - TrueNegatives: 127.5000 - TruePositives: 62.9000 - accuracy: 0.9688 - loss: 0.1123 - precision: 0.9688 - recall: 0.9688 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1904 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 154/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 1.2000 - FalsePositives: 1.2000 - TrueNegatives: 128.0000 - TruePositives: 63.4000 - accuracy: 0.9875 - loss: 0.1185 - precision: 0.9875 - recall: 0.9875 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1821 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 155/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 0.6000 - FalsePositives: 0.6000 - TrueNegatives: 128.6000 - TruePositives: 64.0000 - accuracy: 0.9940 - loss: 0.1097 - precision: 0.9940 - recall: 0.9940 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1727 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 156/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 1.7000 - FalsePositives: 1.7000 - TrueNegatives: 127.5000 - TruePositives: 62.9000 - accuracy: 0.9662 - loss: 0.1372 - precision: 0.9662 - recall: 0.9662 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1792 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 157/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 1.0000 - FalsePositives: 1.0000 - TrueNegatives: 128.2000 - TruePositives: 63.6000 - accuracy: 0.9755 - loss: 0.1429 - precision: 0.9755 - recall: 0.9755 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1785 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 158/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 1.2000 - FalsePositives: 1.2000 - TrueNegatives: 128.0000 - TruePositives: 63.4000 - accuracy: 0.9857 - loss: 0.1166 - precision: 0.9857 - recall: 0.9857 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1782 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 159/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 1.3000 - FalsePositives: 1.3000 - TrueNegatives: 127.9000 - TruePositives: 63.3000 - accuracy: 0.9825 - loss: 0.1165 - precision: 0.9825 - recall: 0.9825 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1789 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 160/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - FalseNegatives: 1.9000 - FalsePositives: 1.9000 - TrueNegatives: 127.3000 - TruePositives: 62.7000 - accuracy: 0.9593 - loss: 0.1506 - precision: 0.9593 - recall: 0.9593 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1763 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 161/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - FalseNegatives: 1.4000 - FalsePositives: 1.4000 - TrueNegatives: 127.8000 - TruePositives: 63.2000 - accuracy: 0.9714 - loss: 0.1289 - precision: 0.9714 - recall: 0.9714 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1688 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 162/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 2.0000 - FalsePositives: 2.0000 - TrueNegatives: 127.2000 - TruePositives: 62.6000 - accuracy: 0.9712 - loss: 0.1249 - precision: 0.9712 - recall: 0.9712 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1710 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 163/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - FalseNegatives: 1.2000 - FalsePositives: 1.2000 - TrueNegatives: 128.0000 - TruePositives: 63.4000 - accuracy: 0.9853 - loss: 0.1227 - precision: 0.9853 - recall: 0.9853 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1744 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 164/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 2.2000 - FalsePositives: 2.2000 - TrueNegatives: 127.0000 - TruePositives: 62.4000 - accuracy: 0.9674 - loss: 0.1269 - precision: 0.9674 - recall: 0.9674 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1795 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 165/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 1.2000 - FalsePositives: 1.2000 - TrueNegatives: 128.0000 - TruePositives: 63.4000 - accuracy: 0.9875 - loss: 0.0911 - precision: 0.9875 - recall: 0.9875 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1757 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 166/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - FalseNegatives: 1.9000 - FalsePositives: 1.9000 - TrueNegatives: 127.3000 - TruePositives: 62.7000 - accuracy: 0.9654 - loss: 0.1213 - precision: 0.9654 - recall: 0.9654 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1605 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 167/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 1.9000 - FalsePositives: 1.9000 - TrueNegatives: 127.3000 - TruePositives: 62.7000 - accuracy: 0.9659 - loss: 0.1031 - precision: 0.9659 - recall: 0.9659 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1696 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 168/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - FalseNegatives: 1.0000 - FalsePositives: 1.0000 - TrueNegatives: 128.2000 - TruePositives: 63.6000 - accuracy: 0.9755 - loss: 0.1242 - precision: 0.9755 - recall: 0.9755 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1658 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 169/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - FalseNegatives: 1.2000 - FalsePositives: 1.2000 - TrueNegatives: 128.0000 - TruePositives: 63.4000 - accuracy: 0.9809 - loss: 0.1070 - precision: 0.9809 - recall: 0.9809 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1711 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 170/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 1.4000 - FalsePositives: 1.4000 - TrueNegatives: 127.8000 - TruePositives: 63.2000 - accuracy: 0.9714 - loss: 0.1261 - precision: 0.9714 - recall: 0.9714 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1686 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 171/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 1.0000 - FalsePositives: 1.0000 - TrueNegatives: 128.2000 - TruePositives: 63.6000 - accuracy: 0.9861 - loss: 0.1133 - precision: 0.9861 - recall: 0.9861 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1712 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 172/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 1.5000 - FalsePositives: 1.5000 - TrueNegatives: 127.7000 - TruePositives: 63.1000 - accuracy: 0.9810 - loss: 0.1219 - precision: 0.9810 - recall: 0.9810 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1705 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 173/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 1.1000 - FalsePositives: 1.1000 - TrueNegatives: 128.1000 - TruePositives: 63.5000 - accuracy: 0.9851 - loss: 0.1138 - precision: 0.9851 - recall: 0.9851 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1594 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 174/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - FalseNegatives: 0.6000 - FalsePositives: 0.6000 - TrueNegatives: 128.6000 - TruePositives: 64.0000 - accuracy: 0.9928 - loss: 0.1202 - precision: 0.9928 - recall: 0.9928 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1601 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 175/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 0.4000 - FalsePositives: 0.4000 - TrueNegatives: 128.8000 - TruePositives: 64.2000 - accuracy: 0.9959 - loss: 0.1151 - precision: 0.9959 - recall: 0.9959 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1586 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 176/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 0.7000 - FalsePositives: 0.7000 - TrueNegatives: 128.5000 - TruePositives: 63.9000 - accuracy: 0.9930 - loss: 0.1147 - precision: 0.9930 - recall: 0.9930 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1564 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 177/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 0.5000 - FalsePositives: 0.5000 - TrueNegatives: 128.7000 - TruePositives: 64.1000 - accuracy: 0.9945 - loss: 0.1156 - precision: 0.9945 - recall: 0.9945 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1708 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 178/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 1.6000 - FalsePositives: 1.6000 - TrueNegatives: 127.6000 - TruePositives: 63.0000 - accuracy: 0.9695 - loss: 0.1036 - precision: 0.9695 - recall: 0.9695 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1681 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 179/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - FalseNegatives: 1.1000 - FalsePositives: 1.1000 - TrueNegatives: 128.1000 - TruePositives: 63.5000 - accuracy: 0.9867 - loss: 0.1120 - precision: 0.9867 - recall: 0.9867 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1550 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 180/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - FalseNegatives: 1.6000 - FalsePositives: 1.6000 - TrueNegatives: 127.6000 - TruePositives: 63.0000 - accuracy: 0.9697 - loss: 0.1355 - precision: 0.9697 - recall: 0.9697 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1455 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 181/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - FalseNegatives: 2.2000 - FalsePositives: 2.2000 - TrueNegatives: 127.0000 - TruePositives: 62.4000 - accuracy: 0.9663 - loss: 0.1095 - precision: 0.9663 - recall: 0.9663 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1632 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 182/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - FalseNegatives: 1.4000 - FalsePositives: 1.4000 - TrueNegatives: 127.8000 - TruePositives: 63.2000 - accuracy: 0.9714 - loss: 0.1039 - precision: 0.9714 - recall: 0.9714 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1629 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 183/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 1.3000 - FalsePositives: 1.3000 - TrueNegatives: 127.9000 - TruePositives: 63.3000 - accuracy: 0.9797 - loss: 0.1024 - precision: 0.9797 - recall: 0.9797 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1509 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 184/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 0.7000 - FalsePositives: 0.7000 - TrueNegatives: 128.5000 - TruePositives: 63.9000 - accuracy: 0.9908 - loss: 0.1063 - precision: 0.9908 - recall: 0.9908 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1541 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 185/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 1.2000 - FalsePositives: 1.2000 - TrueNegatives: 128.0000 - TruePositives: 63.4000 - accuracy: 0.9853 - loss: 0.0983 - precision: 0.9853 - recall: 0.9853 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1545 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 186/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 1.5000 - FalsePositives: 1.5000 - TrueNegatives: 127.7000 - TruePositives: 63.1000 - accuracy: 0.9787 - loss: 0.1046 - precision: 0.9787 - recall: 0.9787 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1558 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 187/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 2.1000 - FalsePositives: 2.1000 - TrueNegatives: 127.1000 - TruePositives: 62.5000 - accuracy: 0.9707 - loss: 0.1014 - precision: 0.9707 - recall: 0.9707 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1435 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 188/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 0.8000 - FalsePositives: 0.8000 - TrueNegatives: 128.4000 - TruePositives: 63.8000 - accuracy: 0.9918 - loss: 0.1038 - precision: 0.9918 - recall: 0.9918 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1637 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 189/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - FalseNegatives: 0.7000 - FalsePositives: 0.7000 - TrueNegatives: 128.5000 - TruePositives: 63.9000 - accuracy: 0.9926 - loss: 0.0870 - precision: 0.9926 - recall: 0.9926 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1585 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 190/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 1.1000 - FalsePositives: 1.1000 - TrueNegatives: 128.1000 - TruePositives: 63.5000 - accuracy: 0.9819 - loss: 0.1031 - precision: 0.9819 - recall: 0.9819 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1569 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 191/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - FalseNegatives: 0.7000 - FalsePositives: 0.7000 - TrueNegatives: 128.5000 - TruePositives: 63.9000 - accuracy: 0.9908 - loss: 0.0880 - precision: 0.9908 - recall: 0.9908 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1406 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 192/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - FalseNegatives: 2.4000 - FalsePositives: 2.4000 - TrueNegatives: 126.8000 - TruePositives: 62.2000 - accuracy: 0.9626 - loss: 0.1198 - precision: 0.9626 - recall: 0.9626 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1384 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 193/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 1.0000 - FalsePositives: 1.0000 - TrueNegatives: 128.2000 - TruePositives: 63.6000 - accuracy: 0.9878 - loss: 0.0778 - precision: 0.9878 - recall: 0.9878 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1530 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 194/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 1.1000 - FalsePositives: 1.1000 - TrueNegatives: 128.1000 - TruePositives: 63.5000 - accuracy: 0.9881 - loss: 0.0892 - precision: 0.9881 - recall: 0.9881 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1675 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 195/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - FalseNegatives: 2.3000 - FalsePositives: 2.3000 - TrueNegatives: 126.9000 - TruePositives: 62.3000 - accuracy: 0.9646 - loss: 0.1050 - precision: 0.9646 - recall: 0.9646 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1419 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 196/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - FalseNegatives: 0.9000 - FalsePositives: 0.9000 - TrueNegatives: 128.3000 - TruePositives: 63.7000 - accuracy: 0.9904 - loss: 0.0992 - precision: 0.9904 - recall: 0.9904 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1420 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 197/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - FalseNegatives: 0.9000 - FalsePositives: 0.9000 - TrueNegatives: 128.3000 - TruePositives: 63.7000 - accuracy: 0.9838 - loss: 0.1049 - precision: 0.9838 - recall: 0.9838 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1540 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 198/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - FalseNegatives: 0.9000 - FalsePositives: 0.9000 - TrueNegatives: 128.3000 - TruePositives: 63.7000 - accuracy: 0.9889 - loss: 0.0952 - precision: 0.9889 - recall: 0.9889 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1524 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 199/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - FalseNegatives: 1.7000 - FalsePositives: 1.7000 - TrueNegatives: 127.5000 - TruePositives: 62.9000 - accuracy: 0.9662 - loss: 0.1099 - precision: 0.9662 - recall: 0.9662 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1416 - val_precision: 0.9500 - val_recall: 0.9500\n",
      "Epoch 200/200\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - FalseNegatives: 0.7000 - FalsePositives: 0.7000 - TrueNegatives: 128.5000 - TruePositives: 63.9000 - accuracy: 0.9908 - loss: 0.0999 - precision: 0.9908 - recall: 0.9908 - val_FalseNegatives: 1.0000 - val_FalsePositives: 1.0000 - val_TrueNegatives: 39.0000 - val_TruePositives: 19.0000 - val_accuracy: 0.9500 - val_loss: 0.1401 - val_precision: 0.9500 - val_recall: 0.9500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x790c99366990>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model!\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=12,\n",
    "          epochs=200,\n",
    "          validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cc7161-1379-4ad8-ad38-3351b4184d11",
   "metadata": {},
   "source": [
    "### 2.4. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de8e5972-bfc3-4246-9999-506786ea38b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - FalseNegatives: 2.0000 - FalsePositives: 2.0000 - TrueNegatives: 44.0000 - TruePositives: 21.0000 - accuracy: 0.9130 - loss: 0.1393 - precision: 0.9130 - recall: 0.9130\n",
      "Test accuracy: 91.30%\n",
      "Test recall: 91.30%\n",
      "Test precision: 91.30%\n",
      "TP: 21.0\n",
      "TN: 44.0\n",
      "FP: 2.0\n",
      "FN: 2.0\n",
      "Test Matthew coefficient: 86.96%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "_, FN, FP, TN, TP, accuracy, precision, recall = model.evaluate(X_test, y_test)\n",
    "mcc = (TP * TN - FP * FN) / np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
    "print(f\"Test accuracy: {accuracy*100:.2f}%\")\n",
    "print(f\"Test recall: {recall*100:.2f}%\")\n",
    "print(f\"Test precision: {precision*100:.2f}%\")\n",
    "print(f\"TP: {TP}\")\n",
    "print(f\"TN: {TN}\")\n",
    "print(f\"FP: {FP}\")\n",
    "print(f\"FN: {FN}\")\n",
    "print(f\"Test Matthew coefficient: {mcc * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
